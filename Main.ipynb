{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Reto 1: Extracción de datos de Facturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
      "   ---------------------------------------- 0.0/463.1 kB ? eta -:--:--\n",
      "   ----------------- --------------------- 204.8/463.1 kB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 463.1/463.1 kB 7.3 MB/s eta 0:00:00\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached numpy-2.2.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "   ---------------------------------------- 0.0/507.9 kB ? eta -:--:--\n",
      "   --------------------------------------  501.8/507.9 kB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 507.9/507.9 kB 7.9 MB/s eta 0:00:00\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 166.4/166.4 kB 9.8 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-extensions, tqdm, sniffio, pillow, numpy, jiter, idna, h11, et-xmlfile, distro, certifi, annotated-types, pydantic-core, pandas, openpyxl, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.8.0 certifi-2025.1.31 distro-1.9.0 et-xmlfile-2.0.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jiter-0.8.2 numpy-2.2.2 openai-1.61.1 openpyxl-3.1.5 pandas-2.2.3 pillow-11.1.0 pydantic-2.10.6 pydantic-core-2.27.2 pytz-2025.1 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.12.2 tzdata-2025.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow pandas openpyxl openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "INPUT_FOLDER = r\"D:\\PruebatecnicaFerreycorp\\GenAI\\Facturas\"\n",
    "OUTPUT_FOLDER = r\"D:\\PruebatecnicaFerreycorp\\GenAI\\Facturas_Procesadas\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_response(response: str) -> str:\n",
    "   \"\"\"\n",
    "   Limpia la respuesta del modelo para obtener solo el JSON válido.\n",
    "\n",
    "   Args:\n",
    "       response (str): Respuesta completa del modelo\n",
    "\n",
    "   Returns:\n",
    "       str: JSON limpio\n",
    "   \"\"\"\n",
    "   # Buscar el contenido JSON entre llaves\n",
    "   json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "   if json_match:\n",
    "       return json_match.group(0)\n",
    "   return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_jpg(input_path: str, output_path: str) -> str | None:\n",
    "   \"\"\"\n",
    "   Convierte una imagen a formato JPG.\n",
    "\n",
    "   Args:\n",
    "       input_path (str): Ruta de la imagen de entrada\n",
    "       output_path (str): Ruta donde se guardará la imagen convertida\n",
    "\n",
    "   Returns:\n",
    "       str | None: Ruta de la imagen convertida o None si hay error\n",
    "   \"\"\"\n",
    "   try:\n",
    "       with Image.open(input_path) as img:\n",
    "           if img.mode in ('RGBA', 'P'):\n",
    "               img = img.convert('RGB')\n",
    "           img.save(output_path, 'JPEG')\n",
    "       return output_path\n",
    "   except Exception as e:\n",
    "       print(f\"Error al convertir la imagen: {e}\")\n",
    "       return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Analiza una imagen usando Gpt-4o-mini Vision para extraer información de la factura.\n",
    "    Utiliza Chain of Thought (CoT) prompting para mejorar la extracción.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta de la imagen a analizar\n",
    "\n",
    "    Returns:\n",
    "        str: Respuesta del modelo en formato JSON\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    prompt = \"\"\"Analiza la factura paso a paso:\n",
    "\n",
    "    1. Primero, identifica el logo o nombre de la empresa en la parte superior de la factura.\n",
    "    2. Busca el número de factura (puede aparecer como Order No., Reference No., o Invoice No.).\n",
    "    3. Encuentra la fecha de emisión (generalmente aparece como Invoice Date o Date), si encuentras en texto ponlo en formato dia/mes/año.\n",
    "    4. Localiza el monto total (busca términos como Total, Total Order, Amount).\n",
    "    5. Determina la moneda utilizada (USD, PEN, etc.).\n",
    "    OBSERVACION: Si no encuentras o no se puede visualizar los items pedidos escribe \"None\"\n",
    "\n",
    "    Después de analizar estos elementos, devuelve SOLO un objeto JSON con este formato exacto \n",
    "    (sin markdown, sin ```json, sin comentarios adicionales):\n",
    "    {\n",
    "        \"proveedor\": \"nombre de la empresa que emite la factura\",\n",
    "        \"factura\": \"número de factura\",\n",
    "        \"fecha_de_factura\": \"fecha de emisión\",\n",
    "        \"monto\": \"monto total\",\n",
    "        \"moneda\": \"moneda\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    print(\"\\nJSON reconocido:\")\n",
    "    print(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images() -> list:\n",
    "   \"\"\"\n",
    "   Procesa todas las imágenes en el directorio de entrada.\n",
    "\n",
    "   Returns:\n",
    "       list: Lista de diccionarios con la información extraída de cada factura\n",
    "   \"\"\"\n",
    "   results = []\n",
    "   \n",
    "   if not os.path.exists(OUTPUT_FOLDER):\n",
    "       os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "   for filename in os.listdir(INPUT_FOLDER):\n",
    "       if filename.lower().endswith(('.jpg', '.jpeg', '.jfif')):\n",
    "           input_path = os.path.join(INPUT_FOLDER, filename)\n",
    "           output_path = os.path.join(OUTPUT_FOLDER, f\"{os.path.splitext(filename)[0]}.jpg\")\n",
    "           \n",
    "           final_path = convert_to_jpg(input_path, output_path)\n",
    "           if final_path:\n",
    "               print(f\"Procesando: {filename}\")\n",
    "               try:\n",
    "                   # Obtener y limpiar la respuesta\n",
    "                   raw_analysis = analyze_image(final_path)\n",
    "                   cleaned_json = clean_json_response(raw_analysis)\n",
    "                   \n",
    "                   # Parsear el JSON limpio\n",
    "                   json_data = json.loads(cleaned_json)\n",
    "                   results.append(json_data)\n",
    "                   print(f\"Análisis completado para: {filename}\")\n",
    "               except json.JSONDecodeError as e:\n",
    "                   print(f\"Error al procesar JSON para {filename}: {e}\")\n",
    "                   print(\"Respuesta recibida:\", raw_analysis)\n",
    "                   print(\"JSON limpio intentado:\", cleaned_json)\n",
    "               print(\"-\" * 50)\n",
    "\n",
    "   return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el proceso completo y muestra resultados detallados.\n",
    "    \"\"\"\n",
    "    results = process_images()\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\nDetalles del DataFrame:\")\n",
    "    print(\"----------------------\")\n",
    "    print(\"Dimensiones:\", df.shape)\n",
    "    print(\"\\nColumnas:\", list(df.columns))\n",
    "    print(\"\\nPrimeras filas:\")\n",
    "    print(df)\n",
    "    print(\"\\nResumen estadístico:\")\n",
    "    print(df.describe(include='all'))\n",
    "    df.to_excel(\"resultados_facturas.xlsx\", index=False)\n",
    "    print(\"\\nResultados guardados en 'resultados_facturas.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: factura1.jpg\n",
      "\n",
      "JSON reconocido:\n",
      "{\n",
      "    \"proveedor\": \"B&H\",\n",
      "    \"factura\": \"Reference No.: 1286390\",\n",
      "    \"fecha_de_factura\": \"06/09/11\",\n",
      "    \"monto\": \"249.00\",\n",
      "    \"moneda\": \"USD\"\n",
      "}\n",
      "Análisis completado para: factura1.jpg\n",
      "--------------------------------------------------\n",
      "Procesando: factura2.jfif\n",
      "\n",
      "JSON reconocido:\n",
      "{\n",
      "    \"proveedor\": \"CONFECCIONES \\\"SAN JORGE\\\" S.A.C.\",\n",
      "    \"factura\": \"0000765\",\n",
      "    \"fecha_de_factura\": \"15/10/2013\",\n",
      "    \"monto\": \"1,156.40\",\n",
      "    \"moneda\": \"nuevos soles\"\n",
      "}\n",
      "Análisis completado para: factura2.jfif\n",
      "--------------------------------------------------\n",
      "\n",
      "Detalles del DataFrame:\n",
      "----------------------\n",
      "Dimensiones: (2, 5)\n",
      "\n",
      "Columnas: ['proveedor', 'factura', 'fecha_de_factura', 'monto', 'moneda']\n",
      "\n",
      "Primeras filas:\n",
      "                         proveedor                 factura fecha_de_factura  \\\n",
      "0                              B&H  Reference No.: 1286390         06/09/11   \n",
      "1  CONFECCIONES \"SAN JORGE\" S.A.C.                 0000765       15/10/2013   \n",
      "\n",
      "      monto        moneda  \n",
      "0    249.00           USD  \n",
      "1  1,156.40  nuevos soles  \n",
      "\n",
      "Resumen estadístico:\n",
      "       proveedor                 factura fecha_de_factura   monto moneda\n",
      "count          2                       2                2       2      2\n",
      "unique         2                       2                2       2      2\n",
      "top          B&H  Reference No.: 1286390         06/09/11  249.00    USD\n",
      "freq           1                       1                1       1      1\n",
      "\n",
      "Resultados guardados en 'resultados_facturas.xlsx'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reto 2: Evaluar procedimiento de cocina a partir de una receta y videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (1.61.1)\n",
      "Requirement already satisfied: opencv-python in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: PyPDF2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (3.0.1)\n",
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from opencv-python) (2.2.2)\n",
      "Requirement already satisfied: pillow in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pdf2image) (11.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai opencv-python PyPDF2 pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen guardada: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\imagenes_receta\\receta_pagina_1.jpg\n",
      "Imagen guardada: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\imagenes_receta\\receta_pagina_2.jpg\n",
      "Imagen guardada: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\imagenes_receta\\receta_pagina_3.jpg\n",
      "\n",
      "Se generaron 3 imágenes de la receta\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def convertir_y_guardar_pdf(ruta_pdf: str, directorio_salida: str) -> list:\n",
    "    \"\"\"\n",
    "    Convierte un PDF a imágenes JPG y las guarda en un directorio.\n",
    "    \n",
    "    Args:\n",
    "        ruta_pdf: Ruta al archivo PDF\n",
    "        directorio_salida: Directorio donde se guardarán las imágenes\n",
    "        \n",
    "    Returns:\n",
    "        Lista con las rutas de las imágenes guardadas\n",
    "    \"\"\"\n",
    "    # Crear directorio si no existe\n",
    "    if not os.path.exists(directorio_salida):\n",
    "        os.makedirs(directorio_salida)\n",
    "    \n",
    "    # Convertir PDF a imágenes\n",
    "    imagenes = convert_from_path(ruta_pdf)\n",
    "    rutas_guardadas = []\n",
    "    \n",
    "    # Guardar cada imagen\n",
    "    for i, imagen in enumerate(imagenes):\n",
    "        # Convertir imagen PIL a array numpy\n",
    "        img_array = np.array(imagen)\n",
    "        # Convertir de RGB a BGR (formato OpenCV)\n",
    "        img_cv2 = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Generar nombre de archivo\n",
    "        nombre_archivo = f'receta_pagina_{i+1}.jpg'\n",
    "        ruta_completa = os.path.join(directorio_salida, nombre_archivo)\n",
    "        \n",
    "        # Guardar imagen\n",
    "        cv2.imwrite(ruta_completa, img_cv2)\n",
    "        rutas_guardadas.append(ruta_completa)\n",
    "        print(f\"Imagen guardada: {ruta_completa}\")\n",
    "    \n",
    "    return rutas_guardadas\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurar rutas\n",
    "    directorio_base = \"D:\\\\PruebatecnicaFerreycorp\\\\GenAI\\\\Videos y Receta\"\n",
    "    ruta_pdf = os.path.join(directorio_base, \"receta-panqueques.pdf\")\n",
    "    directorio_imagenes = os.path.join(directorio_base, \"imagenes_receta\")\n",
    "    \n",
    "    try:\n",
    "        # Convertir PDF y guardar imágenes\n",
    "        rutas_imagenes = convertir_y_guardar_pdf(ruta_pdf, directorio_imagenes)\n",
    "        print(f\"\\nSe generaron {len(rutas_imagenes)} imágenes de la receta\")\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pydantic in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "   ---------------------------------------- 0.0/175.4 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 122.9/175.4 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 175.4/175.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.1/1.3 MB 4.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.3 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.3 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.7/1.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.9/1.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.1/160.1 kB 3.2 MB/s eta 0:00:00\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.8 MB 6.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/12.8 MB 5.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/12.8 MB 5.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.2/12.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.5/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.8/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.5/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.9/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.2/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.6/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.3/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.5/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.7/12.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.1/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.4/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.7/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.0/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.8/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.1/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.3/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.8/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.5/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.8/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.1/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.3/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.6/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.9/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 6.8 MB/s eta 0:00:00\n",
      "Using cached cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, protobuf, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed cachetools-5.5.1 google-ai-generativelanguage-0.6.15 google-api-core-2.24.1 google-api-python-client-2.160.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 googleapis-common-protos-1.66.0 grpcio-1.70.0 grpcio-status-1.70.0 httplib2-0.22.0 proto-plus-1.26.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.1 rsa-4.9 uritemplate-4.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando información general de la receta...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_1.jpg:\n",
      "{\n",
      "    \"ingredientes\": [\"1 taza de harina leudante o harina de repostería\", \"1 huevo\", \"¾ taza de leche\", \"1 chorro de pequeño de aceite de oliva\", \"1 cucharadita de mantequilla\", \"1 chorro de miel\"],\n",
      "    \"utensilios\": [\"Moldes para panqueques\", \"Espátula de silicona\", \"Sartén de panqueques (opcional)\", \"Bol\"],\n",
      "    \"tiempo_preparacion\": \"15 minutos\",\n",
      "    \"porciones\": \"2 porciones\",\n",
      "    \"dificultad\": \"baja\"\n",
      "}\n",
      "\n",
      "Buscando pasos en receta_pagina_1.jpg...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_1.jpg:\n",
      "Lo siento, pero no puedo extraer los pasos numerados de la receta de la imagen que has proporcionado.\n",
      "\n",
      "Buscando pasos en receta_pagina_2.jpg...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_2.jpg:\n",
      "```json\n",
      "{\n",
      "    \"pasos\": {\n",
      "        \"1\": \"Hacer la receta de panqueques es súper fácil. Primero, reúne todos los ingredientes. Si no tienes harina leudante o preparada, que es harina de trigo que ya incluye levadura (también se llama harina de repostería), puedes usar harina de trigo normal y añadir una cucharadita de levadura química en polvo (polvo de hornear).\",\n",
      "        \"2\": \"Coloca la harina en un bol y añade el huevo y la leche. Mezcla bien hasta que se integren estos ingredientes y no queden casi grumos.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "Buscando pasos en receta_pagina_3.jpg...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_3.jpg:\n",
      "```json\n",
      "{\n",
      "    \"pasos\": {\n",
      "        \"3\": \"Para terminar de hacer la masa de los panqueques caseros, agrega un chorrito de aceite y mezcla bien. Verás que el aceite hace que se terminen de disolver los grumos de harina y quede una masa lisa y homogénea. Truco: si la masa está muy espesa puedes añadir un poco más de leche.\",\n",
      "        \"4\": \"Para hacer los panqueques, calienta una sartén a fuego medio-bajo con un poquito de aceite o mantequilla. Cuando la sartén esté caliente, añade una cucharada de mezcla y déjala al fuego hasta que empiecen a salir burbujas en la superficie, entonces dale la vuelta y cocina por el otro lado.\",\n",
      "        \"5\": \"Para servir la receta de panqueques súper fáciles de hacer, añade un poquito de mantequilla y miel y a disfrutar. Si quieres comerlos con algo salado, puedes servirlos con bacon y huevos fritos o un revuelto con jamón.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "Resultados guardados en: analisis_receta_detallado.json\n",
      "\n",
      "Resumen del análisis:\n",
      "Total de pasos: 5\n",
      "Tiempo de preparación: 15 minutos\n",
      "Dificultad: baja\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import cv2\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "class RecetaAgent:\n",
    "    def __init__(self):\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"No se encontró la API key de OpenAI\")\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.info_receta = {\n",
    "            'ingredientes': [],\n",
    "            'utensilios': [],\n",
    "            'tiempo_preparacion': '',\n",
    "            'porciones': '',\n",
    "            'dificultad': '',\n",
    "            'pasos': {}\n",
    "        }\n",
    "        self.resultados_json = {\n",
    "            'analisis_general': {},\n",
    "            'pasos': [],\n",
    "            'metadatos': {\n",
    "                'total_pasos': 0,\n",
    "                'tiempo_total': '',\n",
    "                'nivel_dificultad': ''\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def analizar_imagen(self, ruta_imagen: str, es_primera_pagina: bool = False) -> Dict:\n",
    "        \"\"\"Analiza una imagen de la receta usando GPT-4 Vision.\"\"\"\n",
    "        imagen = cv2.imread(ruta_imagen)\n",
    "        _, buffer = cv2.imencode('.jpg', imagen)\n",
    "        imagen_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "        if es_primera_pagina:\n",
    "            prompt = \"\"\"\n",
    "            Extrae la siguiente información de la receta y responde EXACTAMENTE en este formato:\n",
    "            {\n",
    "                \"ingredientes\": [\"ingrediente1\", \"ingrediente2\", ...],\n",
    "                \"utensilios\": [\"utensilio1\", \"utensilio2\", ...],\n",
    "                \"tiempo_preparacion\": \"X minutos\",\n",
    "                \"porciones\": \"X porciones\",\n",
    "                \"dificultad\": \"nivel\"\n",
    "            }\n",
    "            \"\"\"\n",
    "        else:\n",
    "            prompt = \"\"\"\n",
    "            Extrae los pasos numerados de la receta en este formato:\n",
    "            {\n",
    "                \"pasos\": {\n",
    "                    \"1\": \"descripción completa del paso 1\",\n",
    "                    \"2\": \"descripción completa del paso 2\"\n",
    "                }\n",
    "            }\n",
    "            \"\"\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{imagen_base64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1000\n",
    "        )\n",
    "\n",
    "        respuesta_texto = response.choices[0].message.content\n",
    "        print(f\"\\nRespuesta de GPT para {os.path.basename(ruta_imagen)}:\")\n",
    "        print(respuesta_texto)\n",
    "        \n",
    "        try:\n",
    "            inicio_json = respuesta_texto.find('{')\n",
    "            fin_json = respuesta_texto.rfind('}') + 1\n",
    "            if inicio_json != -1 and fin_json != 0:\n",
    "                json_str = respuesta_texto[inicio_json:fin_json]\n",
    "                return json.loads(json_str)\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar JSON: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def procesar_receta(self, directorio_imagenes: str) -> Dict:\n",
    "        \"\"\"Procesa todas las imágenes de la receta y guarda los resultados.\"\"\"\n",
    "        archivos = sorted([f for f in os.listdir(directorio_imagenes) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        \n",
    "        # Procesar primera página\n",
    "        if archivos:\n",
    "            print(\"\\nAnalizando información general de la receta...\")\n",
    "            info_primera_pagina = self.analizar_imagen(\n",
    "                os.path.join(directorio_imagenes, archivos[0]), \n",
    "                es_primera_pagina=True\n",
    "            )\n",
    "            \n",
    "            # Actualizar información general\n",
    "            self.info_receta.update({\n",
    "                'ingredientes': info_primera_pagina.get('ingredientes', []),\n",
    "                'utensilios': info_primera_pagina.get('utensilios', []),\n",
    "                'tiempo_preparacion': info_primera_pagina.get('tiempo_preparacion', ''),\n",
    "                'porciones': info_primera_pagina.get('porciones', ''),\n",
    "                'dificultad': info_primera_pagina.get('dificultad', '')\n",
    "            })\n",
    "            \n",
    "            # Actualizar JSON de resultados\n",
    "            self.resultados_json['analisis_general'] = info_primera_pagina\n",
    "            self.resultados_json['metadatos']['nivel_dificultad'] = info_primera_pagina.get('dificultad', '')\n",
    "            self.resultados_json['metadatos']['tiempo_total'] = info_primera_pagina.get('tiempo_preparacion', '')\n",
    "\n",
    "        # Procesar resto de páginas buscando pasos\n",
    "        for archivo in archivos:\n",
    "            print(f\"\\nBuscando pasos en {archivo}...\")\n",
    "            resultado = self.analizar_imagen(os.path.join(directorio_imagenes, archivo))\n",
    "            if 'pasos' in resultado:\n",
    "                self.info_receta['pasos'].update(resultado['pasos'])\n",
    "                for num_paso, descripcion in resultado['pasos'].items():\n",
    "                    self.resultados_json['pasos'].append({\n",
    "                        'numero': num_paso,\n",
    "                        'descripcion': descripcion\n",
    "                    })\n",
    "\n",
    "        self.resultados_json['metadatos']['total_pasos'] = len(self.resultados_json['pasos'])\n",
    "        return self.resultados_json\n",
    "\n",
    "    def guardar_resultados(self, ruta_salida: str = \"analisis_receta.json\"):\n",
    "        \"\"\"Guarda los resultados en un archivo JSON.\"\"\"\n",
    "        with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.resultados_json, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"\\nResultados guardados en: {ruta_salida}\")\n",
    "\n",
    "def main():\n",
    "    # Configurar directorio de imágenes\n",
    "    directorio_base = \"D:\\\\PruebatecnicaFerreycorp\\\\GenAI\\\\Videos y Receta\"\n",
    "    directorio_imagenes = os.path.join(directorio_base, \"imagenes_receta\")\n",
    "    \n",
    "    if not os.path.exists(directorio_imagenes):\n",
    "        raise ValueError(f\"No se encontró el directorio de imágenes: {directorio_imagenes}\")\n",
    "    \n",
    "    # Crear y ejecutar el agente\n",
    "    agente = RecetaAgent()\n",
    "    resultados = agente.procesar_receta(directorio_imagenes)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    agente.guardar_resultados(\"analisis_receta_detallado.json\")\n",
    "    \n",
    "    # Imprimir resumen\n",
    "    print(\"\\nResumen del análisis:\")\n",
    "    print(f\"Total de pasos: {resultados['metadatos']['total_pasos']}\")\n",
    "    print(f\"Tiempo de preparación: {resultados['metadatos']['tiempo_total']}\")\n",
    "    print(f\"Dificultad: {resultados['metadatos']['nivel_dificultad']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PruebatecnicaFerreycorp\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando video: preparacion1.mp4\n",
      "Duración total del video: 06:37\n",
      "Total de frames: 11923\n",
      "FPS: 29.98881571188469\n",
      "\n",
      "Analizando paso 1 en tiempo 00:00\n",
      "Progreso: 0/11923 frames (0.0%)\n",
      "\n",
      "Analizando paso 2 en tiempo 00:09\n",
      "Progreso: 299/11923 frames (2.5%)\n",
      "\n",
      "Analizando paso 3 en tiempo 00:19\n",
      "Progreso: 598/11923 frames (5.0%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:29\n",
      "Progreso: 897/11923 frames (7.5%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:39\n",
      "Progreso: 1196/11923 frames (10.0%)\n",
      "\n",
      "Analizando paso 5 en tiempo 00:49\n",
      "Progreso: 1495/11923 frames (12.5%)\n",
      "\n",
      "Analizando paso 5 en tiempo 00:59\n",
      "Progreso: 1794/11923 frames (15.0%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:09\n",
      "Progreso: 2093/11923 frames (17.6%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:19\n",
      "Progreso: 2392/11923 frames (20.1%)\n",
      "Progreso: 2691/11923 frames (22.6%)\n",
      "Progreso: 2990/11923 frames (25.1%)\n",
      "Progreso: 3289/11923 frames (27.6%)\n",
      "Progreso: 3588/11923 frames (30.1%)\n",
      "Progreso: 3887/11923 frames (32.6%)\n",
      "Progreso: 4186/11923 frames (35.1%)\n",
      "Progreso: 4485/11923 frames (37.6%)\n",
      "Progreso: 4784/11923 frames (40.1%)\n",
      "Progreso: 5083/11923 frames (42.6%)\n",
      "Progreso: 5382/11923 frames (45.1%)\n",
      "Progreso: 5681/11923 frames (47.6%)\n",
      "Progreso: 5980/11923 frames (50.2%)\n",
      "Progreso: 6279/11923 frames (52.7%)\n",
      "Progreso: 6578/11923 frames (55.2%)\n",
      "Progreso: 6877/11923 frames (57.7%)\n",
      "Progreso: 7176/11923 frames (60.2%)\n",
      "Progreso: 7475/11923 frames (62.7%)\n",
      "Progreso: 7774/11923 frames (65.2%)\n",
      "Progreso: 8073/11923 frames (67.7%)\n",
      "Progreso: 8372/11923 frames (70.2%)\n",
      "Progreso: 8671/11923 frames (72.7%)\n",
      "Progreso: 8970/11923 frames (75.2%)\n",
      "Progreso: 9269/11923 frames (77.7%)\n",
      "Progreso: 9568/11923 frames (80.2%)\n",
      "Progreso: 9867/11923 frames (82.8%)\n",
      "Progreso: 10166/11923 frames (85.3%)\n",
      "Progreso: 10465/11923 frames (87.8%)\n",
      "Progreso: 10764/11923 frames (90.3%)\n",
      "Progreso: 11063/11923 frames (92.8%)\n",
      "Progreso: 11362/11923 frames (95.3%)\n",
      "Progreso: 11661/11923 frames (97.8%)\n",
      "\n",
      "Análisis guardado en: analisis_video_1.txt\n",
      "\n",
      "Analizando video: preparacion2.mp4\n",
      "Duración total del video: 06:32\n",
      "Total de frames: 11771\n",
      "FPS: 30.00305612643748\n",
      "\n",
      "Analizando paso 1 en tiempo 00:00\n",
      "Progreso: 0/11771 frames (0.0%)\n",
      "\n",
      "Analizando paso 1 en tiempo 00:09\n",
      "Progreso: 300/11771 frames (2.5%)\n",
      "\n",
      "Analizando paso 2 en tiempo 00:19\n",
      "Progreso: 600/11771 frames (5.1%)\n",
      "\n",
      "Analizando paso 3 en tiempo 00:29\n",
      "Progreso: 900/11771 frames (7.6%)\n",
      "\n",
      "Analizando paso 3 en tiempo 00:39\n",
      "Progreso: 1200/11771 frames (10.2%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:49\n",
      "Progreso: 1500/11771 frames (12.7%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:59\n",
      "Progreso: 1800/11771 frames (15.3%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:09\n",
      "Progreso: 2100/11771 frames (17.8%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:19\n",
      "Límite de API alcanzado, esperando 60 segundos...\n",
      "Progreso: 2400/11771 frames (20.4%)\n",
      "Progreso: 2700/11771 frames (22.9%)\n",
      "Progreso: 3000/11771 frames (25.5%)\n",
      "Progreso: 3300/11771 frames (28.0%)\n",
      "Progreso: 3600/11771 frames (30.6%)\n",
      "Progreso: 3900/11771 frames (33.1%)\n",
      "Progreso: 4200/11771 frames (35.7%)\n",
      "Progreso: 4500/11771 frames (38.2%)\n",
      "Progreso: 4800/11771 frames (40.8%)\n",
      "Progreso: 5100/11771 frames (43.3%)\n",
      "Progreso: 5400/11771 frames (45.9%)\n",
      "Progreso: 5700/11771 frames (48.4%)\n",
      "Progreso: 6000/11771 frames (51.0%)\n",
      "Progreso: 6300/11771 frames (53.5%)\n",
      "Progreso: 6600/11771 frames (56.1%)\n",
      "Progreso: 6900/11771 frames (58.6%)\n",
      "Progreso: 7200/11771 frames (61.2%)\n",
      "Progreso: 7500/11771 frames (63.7%)\n",
      "Progreso: 7800/11771 frames (66.3%)\n",
      "Progreso: 8100/11771 frames (68.8%)\n",
      "Progreso: 8400/11771 frames (71.4%)\n",
      "Progreso: 8700/11771 frames (73.9%)\n",
      "Progreso: 9000/11771 frames (76.5%)\n",
      "Progreso: 9300/11771 frames (79.0%)\n",
      "Progreso: 9600/11771 frames (81.6%)\n",
      "Progreso: 9900/11771 frames (84.1%)\n",
      "Progreso: 10200/11771 frames (86.7%)\n",
      "Progreso: 10500/11771 frames (89.2%)\n",
      "Progreso: 10800/11771 frames (91.8%)\n",
      "Progreso: 11100/11771 frames (94.3%)\n",
      "Progreso: 11400/11771 frames (96.8%)\n",
      "Progreso: 11700/11771 frames (99.4%)\n",
      "\n",
      "Análisis guardado en: analisis_video_2.txt\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from typing import Dict, List\n",
    "\n",
    "class VideoAnalysisAgent:\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "        self.receta_info = self._cargar_receta()\n",
    "        \n",
    "    def _cargar_receta(self, ruta_json: str = \"D:\\\\PruebatecnicaFerreycorp\\\\analisis_receta_detallado.json\") -> Dict:\n",
    "        \"\"\"Carga la información de la receta desde el JSON.\"\"\"\n",
    "        with open(ruta_json, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _formatear_tiempo(self, segundos: float) -> str:\n",
    "        \"\"\"Convierte segundos a formato MM:SS.\"\"\"\n",
    "        tiempo = timedelta(seconds=int(segundos))\n",
    "        return str(tiempo).split('.')[0][-5:]  # Obtiene solo MM:SS\n",
    "    \n",
    "    def analizar_frame(self, frame, timestamp: float, paso_actual: Dict) -> Dict:\n",
    "        \"\"\"Analiza un frame específico del video.\"\"\"\n",
    "        try:\n",
    "            # Convertir frame a formato para Gemini\n",
    "            _, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame_data = buffer.tobytes()\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            Analiza este frame del video de cocina y compáralo con el siguiente paso de la receta:\n",
    "            \n",
    "            Paso {paso_actual['numero']}: {paso_actual['descripcion']}\n",
    "            \n",
    "            Ingredientes necesarios: {self.receta_info['analisis_general']['ingredientes']}\n",
    "            \n",
    "            IMPORTANTE: Tu respuesta debe ser EXACTAMENTE en este formato JSON, sin texto adicional:\n",
    "            {{\n",
    "                \"timestamp\": \"{self._formatear_tiempo(timestamp)}\",\n",
    "                \"accion_detectada\": \"descripción detallada de la acción que se observa\",\n",
    "                \"coincide_con_paso\": true/false,\n",
    "                \"error\": \"descripción del error si existe, o 'None' si no hay error\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            time.sleep(2)  # Pausa para evitar límites de API\n",
    "            \n",
    "            response = self.model.generate_content([\n",
    "                {\"mime_type\": \"image/jpeg\", \"data\": frame_data},\n",
    "                prompt\n",
    "            ])\n",
    "            \n",
    "            # Intentar encontrar y extraer el JSON de la respuesta\n",
    "            try:\n",
    "                texto_respuesta = response.text\n",
    "                inicio_json = texto_respuesta.find('{')\n",
    "                fin_json = texto_respuesta.rfind('}') + 1\n",
    "                \n",
    "                if inicio_json != -1 and fin_json > inicio_json:\n",
    "                    json_str = texto_respuesta[inicio_json:fin_json]\n",
    "                    return json.loads(json_str)\n",
    "                else:\n",
    "                    print(f\"No se encontró JSON válido en la respuesta: {texto_respuesta[:100]}...\")\n",
    "                    return None\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decodificando JSON en timestamp {timestamp}: {str(e)}\")\n",
    "                print(f\"Respuesta recibida: {texto_respuesta[:100]}...\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):\n",
    "                print(\"Límite de API alcanzado, esperando 60 segundos...\")\n",
    "                time.sleep(60)\n",
    "                return self.analizar_frame(frame, timestamp, paso_actual)\n",
    "            print(f\"Error analizando frame: {e}\")\n",
    "            return None\n",
    "\n",
    "    def analizar_video(self, ruta_video: str, nombre_salida: str):\n",
    "        \"\"\"Analiza un video completo y genera el reporte.\"\"\"\n",
    "        print(f\"\\nAnalizando video: {os.path.basename(ruta_video)}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(ruta_video)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        total_duration = total_frames / fps\n",
    "        \n",
    "        resultados = []\n",
    "        paso_actual_idx = 0\n",
    "        frame_interval = int(fps * 10)  # Aumentado a 10 segundos para reducir llamadas a la API\n",
    "        inicio_paso_actual = 0\n",
    "        \n",
    "        print(f\"Duración total del video: {self._formatear_tiempo(total_duration)}\")\n",
    "        print(f\"Total de frames: {total_frames}\")\n",
    "        print(f\"FPS: {fps}\")\n",
    "        \n",
    "        for frame_idx in range(0, total_frames, frame_interval):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            timestamp = frame_idx / fps\n",
    "            \n",
    "            # Si estamos al final de un paso o si detectamos un cambio significativo\n",
    "            if paso_actual_idx < len(self.receta_info['pasos']):\n",
    "                paso_actual = self.receta_info['pasos'][paso_actual_idx]\n",
    "                \n",
    "                print(f\"\\nAnalizando paso {paso_actual['numero']} en tiempo {self._formatear_tiempo(timestamp)}\")\n",
    "                analisis = self.analizar_frame(frame, timestamp, paso_actual)\n",
    "                \n",
    "                if analisis:\n",
    "                    # Si detectamos una acción significativa\n",
    "                    resultados.append({\n",
    "                        \"paso\": f\"**Paso {paso_actual['numero']}**\",\n",
    "                        \"start\": self._formatear_tiempo(inicio_paso_actual),\n",
    "                        \"end\": self._formatear_tiempo(timestamp),\n",
    "                        \"action\": analisis['accion_detectada'],\n",
    "                        \"label\": \"CORRECT\" if analisis.get('coincide_con_paso', False) and (not analisis.get('error') or analisis['error'] == 'None') else \"WRONG\",\n",
    "                        \"error\": analisis.get('error', 'None')\n",
    "                    })\n",
    "                    \n",
    "                    if analisis.get('coincide_con_paso', False):\n",
    "                        inicio_paso_actual = timestamp\n",
    "                        paso_actual_idx += 1\n",
    "            \n",
    "            print(f\"Progreso: {frame_idx}/{total_frames} frames ({(frame_idx/total_frames*100):.1f}%)\")\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Guardar resultados\n",
    "        with open(nombre_salida, 'w', encoding='utf-8') as f:\n",
    "            for resultado in resultados:\n",
    "                f.write(f\"{resultado['paso']}:\\n\")\n",
    "                f.write(f\"* Start: {resultado['start']}\\n\")\n",
    "                f.write(f\"* End: {resultado['end']}\\n\")\n",
    "                f.write(f\"* Action: {resultado['action']}\\n\")\n",
    "                f.write(f\"* Label: {resultado['label']}\\n\")\n",
    "                f.write(f\"* Error: {resultado['error']}\\n\\n\")\n",
    "        \n",
    "        print(f\"\\nAnálisis guardado en: {nombre_salida}\")\n",
    "\n",
    "def main():\n",
    "    # Configuración\n",
    "    api_key = \"-------------------------\"\n",
    "    directorio_base = \"D:\\\\PruebatecnicaFerreycorp\\\\GenAI\\\\Videos y Receta\"\n",
    "    \n",
    "    # Crear agente\n",
    "    agente = VideoAnalysisAgent(api_key)\n",
    "    \n",
    "    # Analizar videos\n",
    "    videos = [\"preparacion1.mp4\", \"preparacion2.mp4\"]\n",
    "    \n",
    "    for i, video in enumerate(videos, 1):\n",
    "        ruta_video = os.path.join(directorio_base, video)\n",
    "        nombre_salida = f\"analisis_video_{i}.txt\"\n",
    "        agente.analizar_video(ruta_video, nombre_salida)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando archivo: analisis_video_1.txt\n",
      "Archivo procesado y guardado en: analisis_video_1_FINAL.txt\n",
      "\n",
      "Procesando archivo: analisis_video_2.txt\n",
      "Archivo procesado y guardado en: analisis_video_2_FINAL.txt\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "class TitleAnalysisAgent:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "    def extraer_pasos(self, contenido: str) -> list:\n",
    "        \"\"\"Extrae los pasos del texto usando expresiones regulares.\"\"\"\n",
    "        patron = r'\\*\\*Paso \\d+\\*\\*:\\n\\* Start: (.*?)\\n\\* End: (.*?)\\n\\* Action: (.*?)\\n\\* Label: (.*?)\\n\\* Error: (.*?)(?=\\n\\n|\\Z)'\n",
    "        pasos = re.findall(patron, contenido, re.DOTALL)\n",
    "        return pasos\n",
    "    \n",
    "    def generar_titulo(self, accion: str) -> str:\n",
    "        \"\"\"Genera un título descriptivo corto usando GPT-4.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Analiza la siguiente acción de una receta y genera un título descriptivo corto (máximo 4 palabras):\n",
    "\n",
    "        Acción: {accion}\n",
    "\n",
    "        Responde SOLO con el título, sin puntos, comillas ni explicaciones adicionales.\n",
    "        Ejemplo: \"Mezcla de ingredientes\" o \"Preparación de masa\"\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=20,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            return response.choices[0].message.content.strip().strip('\"')\n",
    "        except Exception as e:\n",
    "            print(f\"Error generando título: {e}\")\n",
    "            return \"Paso sin título\"\n",
    "\n",
    "    def procesar_archivo(self, ruta_entrada: str, ruta_salida: str):\n",
    "        \"\"\"Procesa el archivo de análisis y genera una versión con títulos.\"\"\"\n",
    "        try:\n",
    "            # Leer archivo original\n",
    "            with open(ruta_entrada, 'r', encoding='utf-8') as f:\n",
    "                contenido = f.read()\n",
    "            \n",
    "            # Extraer pasos\n",
    "            pasos = self.extraer_pasos(contenido)\n",
    "            \n",
    "            # Generar nuevo contenido con títulos\n",
    "            nuevo_contenido = \"\"\n",
    "            for paso in pasos:\n",
    "                start, end, action, label, error = paso\n",
    "                titulo = self.generar_titulo(action)\n",
    "                \n",
    "                nuevo_contenido += f\"\"\"# {titulo}\n",
    "**Paso**:\n",
    "* Start: {start}\n",
    "* End: {end}\n",
    "* Action: {action}\n",
    "* Label: {label}\n",
    "* Error: {error}\\n\\n\"\"\"\n",
    "            \n",
    "            # Guardar nuevo archivo\n",
    "            with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "                f.write(nuevo_contenido)\n",
    "                \n",
    "            print(f\"Archivo procesado y guardado en: {ruta_salida}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando archivo: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Configuración\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"No se encontró la API key de OpenAI\")\n",
    "    \n",
    "    # Crear agente\n",
    "    agente = TitleAnalysisAgent(api_key)\n",
    "    \n",
    "    # Procesar archivos de análisis\n",
    "    for i in range(1, 3):\n",
    "        archivo_entrada = f\"analisis_video_{i}.txt\"\n",
    "        archivo_salida = f\"analisis_video_{i}_FINAL.txt\"\n",
    "        \n",
    "        if os.path.exists(archivo_entrada):\n",
    "            print(f\"\\nProcesando archivo: {archivo_entrada}\")\n",
    "            agente.procesar_archivo(archivo_entrada, archivo_salida)\n",
    "        else:\n",
    "            print(f\"No se encontró el archivo: {archivo_entrada}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/swarm.git\n",
      "  Cloning https://github.com/openai/swarm.git to c:\\users\\diego\\appdata\\local\\temp\\pip-req-build-eoyzj657\n",
      "  Resolved https://github.com/openai/swarm.git to commit 9db581cecaacea0d46a933d6453c312b034dbf47\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from swarm==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: openai>=1.33.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from swarm==0.1.0) (1.61.1)\n",
      "Collecting pytest (from swarm==0.1.0)\n",
      "  Using cached pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from swarm==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from swarm==0.1.0) (4.67.1)\n",
      "Collecting pre-commit (from swarm==0.1.0)\n",
      "  Downloading pre_commit-4.1.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting instructor (from swarm==0.1.0)\n",
      "  Downloading instructor-1.7.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (2.10.6)\n",
      "Requirement already satisfied: sniffio in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from openai>=1.33.0->swarm==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from tqdm->swarm==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from instructor->swarm==0.1.0) (3.11.12)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->swarm==0.1.0)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from instructor->swarm==0.1.0) (3.1.5)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from instructor->swarm==0.1.0) (2.27.2)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from instructor->swarm==0.1.0)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from instructor->swarm==0.1.0) (9.0.0)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor->swarm==0.1.0)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests->swarm==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests->swarm==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests->swarm==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from requests->swarm==0.1.0) (2025.1.31)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading identify-2.6.7-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pre-commit->swarm==0.1.0) (6.0.2)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting iniconfig (from pytest->swarm==0.1.0)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pytest->swarm==0.1.0) (24.2)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->swarm==0.1.0)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.18.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.33.0->swarm==0.1.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.33.0->swarm==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->swarm==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.33.0->swarm==0.1.0) (0.7.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from typer<1.0.0,>=0.9.0->instructor->swarm==0.1.0) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.9.0->instructor->swarm==0.1.0)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0)\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0) (4.3.6)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading instructor-1.7.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.4/71.4 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading pre_commit-4.1.0-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.6 kB ? eta -:--:--\n",
      "   -------------------------------------- - 215.0/220.6 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 220.6/220.6 kB 3.3 MB/s eta 0:00:00\n",
      "Using cached pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading identify-2.6.7-py2.py3-none-any.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.1/99.1 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/4.3 MB 5.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.4/4.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.6/4.3 MB 4.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.9/4.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.2/4.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.5/4.3 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.7/4.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.0/4.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.7/4.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.1/4.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.3/4.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.7/4.3 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.1/4.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 6.2 MB/s eta 0:00:00\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: swarm\n",
      "  Building wheel for swarm (pyproject.toml): started\n",
      "  Building wheel for swarm (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for swarm: filename=swarm-0.1.0-py3-none-any.whl size=26247 sha256=7f354f4a080cf2eff80b6d663eb0effb50396584e44e9538bcf00510d6839b1d\n",
      "  Stored in directory: C:\\Users\\diego\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-tg29fqdg\\wheels\\7e\\5a\\c8\\4a3701c58e2a546c7be4c838027b5d2f2da5bff63ff1a8c8ee\n",
      "Successfully built swarm\n",
      "Installing collected packages: distlib, shellingham, pluggy, nodeenv, mdurl, iniconfig, identify, filelock, docstring-parser, cfgv, virtualenv, pytest, markdown-it-py, rich, pre-commit, typer, instructor, swarm\n",
      "Successfully installed cfgv-3.4.0 distlib-0.3.9 docstring-parser-0.16 filelock-3.17.0 identify-2.6.7 iniconfig-2.0.0 instructor-1.7.2 markdown-it-py-3.0.0 mdurl-0.1.2 nodeenv-1.9.1 pluggy-1.5.0 pre-commit-4.1.0 pytest-8.3.4 rich-13.9.4 shellingham-1.5.4 swarm-0.1.0 typer-0.15.1 virtualenv-20.29.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/swarm.git 'C:\\Users\\diego\\AppData\\Local\\Temp\\pip-req-build-eoyzj657'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/swarm.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Enrutador de Orquestacion de Agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizando información general de la receta...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_1.jpg:\n",
      "{\n",
      "    \"ingredientes\": [\"1 taza de harina leudante o harina de repostería\", \"1 huevo\", \"¾ taza de leche (180 mililitros)\", \"1 chorro de pequeño de aceite de oliva\", \"1 cucharadita de mantequilla\", \"1 chorro de miel\"],\n",
      "    \"utensilios\": [\"Moldes para panqueques\", \"Espátula de silicona\", \"Sartén de panqueques (opcional)\", \"Bol\"],\n",
      "    \"tiempo_preparacion\": \"15 minutos\",\n",
      "    \"porciones\": \"2 porciones\",\n",
      "    \"dificultad\": \"baja\"\n",
      "}\n",
      "\n",
      "Buscando pasos en receta_pagina_1.jpg...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_1.jpg:\n",
      "Lo siento, pero no puedo extraer texto de imágenes. Sin embargo, si tienes la receta en formato de texto, estaré encantado de ayudarte.\n",
      "\n",
      "Buscando pasos en receta_pagina_2.jpg...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_2.jpg:\n",
      "```json\n",
      "{\n",
      "    \"pasos\": {\n",
      "        \"1\": \"Hacer la receta de panqueques es súper fácil. Primero, reúne todos los ingredientes. Si no tienes harina leudante o preparada, que es harina de trigo que ya incluye levadura (también se llama harina de repostería), puedes usar harina de trigo normal y añadir una cucharadita de levadura química en polvo (polvo de hornear).\",\n",
      "        \"2\": \"Coloca la harina en un bol y añade el huevo y la leche. Mezcla bien hasta que se integren estos ingredientes y no queden casi grumos.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "Buscando pasos en receta_pagina_3.jpg...\n",
      "\n",
      "Respuesta de GPT para receta_pagina_3.jpg:\n",
      "```json\n",
      "{\n",
      "    \"pasos\": {\n",
      "        \"3\": \"Para terminar de hacer la masa de los panqueques caseros, agrega un chorrito de aceite y mezcla bien. Verás que el aceite hace que se terminen de disolver los grumos de harina y quede una masa lisa y homogénea. Truco: si la masa está muy espesa puedes añadir un poco más de leche.\",\n",
      "        \"4\": \"Para hacer los panqueques, calienta una sartén a fuego medio-bajo con un poquito de aceite o mantequilla. Cuando la sartén esté caliente, añade una cucharada de mezcla y déjala al fuego hasta que empiecen a salir burbujas en la superficie, entonces dale la vuelta y cocina por el otro lado.\",\n",
      "        \"5\": \"Para servir la receta de panqueques súper fáciles de hacer, añade un poquito de mantequilla y miel y a disfrutar. Si quieres comerlos con algo salado, puedes servirlos con bacon y huevos fritos o un revuelto con jamón.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "Resultados guardados en: analisis_receta_detallado.json\n",
      "\n",
      "Analizando video: preparacion1.mp4\n",
      "Duración total del video: 06:37\n",
      "Total de frames: 11923\n",
      "FPS: 29.98881571188469\n",
      "\n",
      "Analizando paso 1 en tiempo 00:00\n",
      "Progreso: 0/11923 frames (0.0%)\n",
      "\n",
      "Analizando paso 2 en tiempo 00:09\n",
      "Progreso: 299/11923 frames (2.5%)\n",
      "\n",
      "Analizando paso 3 en tiempo 00:19\n",
      "Progreso: 598/11923 frames (5.0%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:29\n",
      "Progreso: 897/11923 frames (7.5%)\n",
      "\n",
      "Analizando paso 5 en tiempo 00:39\n",
      "Progreso: 1196/11923 frames (10.0%)\n",
      "Progreso: 1495/11923 frames (12.5%)\n",
      "Progreso: 1794/11923 frames (15.0%)\n",
      "Progreso: 2093/11923 frames (17.6%)\n",
      "Progreso: 2392/11923 frames (20.1%)\n",
      "Progreso: 2691/11923 frames (22.6%)\n",
      "Progreso: 2990/11923 frames (25.1%)\n",
      "Progreso: 3289/11923 frames (27.6%)\n",
      "Progreso: 3588/11923 frames (30.1%)\n",
      "Progreso: 3887/11923 frames (32.6%)\n",
      "Progreso: 4186/11923 frames (35.1%)\n",
      "Progreso: 4485/11923 frames (37.6%)\n",
      "Progreso: 4784/11923 frames (40.1%)\n",
      "Progreso: 5083/11923 frames (42.6%)\n",
      "Progreso: 5382/11923 frames (45.1%)\n",
      "Progreso: 5681/11923 frames (47.6%)\n",
      "Progreso: 5980/11923 frames (50.2%)\n",
      "Progreso: 6279/11923 frames (52.7%)\n",
      "Progreso: 6578/11923 frames (55.2%)\n",
      "Progreso: 6877/11923 frames (57.7%)\n",
      "Progreso: 7176/11923 frames (60.2%)\n",
      "Progreso: 7475/11923 frames (62.7%)\n",
      "Progreso: 7774/11923 frames (65.2%)\n",
      "Progreso: 8073/11923 frames (67.7%)\n",
      "Progreso: 8372/11923 frames (70.2%)\n",
      "Progreso: 8671/11923 frames (72.7%)\n",
      "Progreso: 8970/11923 frames (75.2%)\n",
      "Progreso: 9269/11923 frames (77.7%)\n",
      "Progreso: 9568/11923 frames (80.2%)\n",
      "Progreso: 9867/11923 frames (82.8%)\n",
      "Progreso: 10166/11923 frames (85.3%)\n",
      "Progreso: 10465/11923 frames (87.8%)\n",
      "Progreso: 10764/11923 frames (90.3%)\n",
      "Progreso: 11063/11923 frames (92.8%)\n",
      "Progreso: 11362/11923 frames (95.3%)\n",
      "Progreso: 11661/11923 frames (97.8%)\n",
      "\n",
      "Análisis guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos sin titulos\\analisis_video_1.txt\n",
      "\n",
      "Analizando video: preparacion2.mp4\n",
      "Duración total del video: 06:32\n",
      "Total de frames: 11771\n",
      "FPS: 30.00305612643748\n",
      "\n",
      "Analizando paso 1 en tiempo 00:00\n",
      "Progreso: 0/11771 frames (0.0%)\n",
      "\n",
      "Analizando paso 2 en tiempo 00:09\n",
      "Progreso: 300/11771 frames (2.5%)\n",
      "\n",
      "Analizando paso 3 en tiempo 00:19\n",
      "Progreso: 600/11771 frames (5.1%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:29\n",
      "Progreso: 900/11771 frames (7.6%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:39\n",
      "Progreso: 1200/11771 frames (10.2%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:49\n",
      "Progreso: 1500/11771 frames (12.7%)\n",
      "\n",
      "Analizando paso 4 en tiempo 00:59\n",
      "Límite de API alcanzado, esperando 60 segundos...\n",
      "Progreso: 1800/11771 frames (15.3%)\n",
      "\n",
      "Analizando paso 4 en tiempo 01:09\n",
      "Progreso: 2100/11771 frames (17.8%)\n",
      "\n",
      "Analizando paso 4 en tiempo 01:19\n",
      "Progreso: 2400/11771 frames (20.4%)\n",
      "\n",
      "Analizando paso 4 en tiempo 01:29\n",
      "Progreso: 2700/11771 frames (22.9%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:39\n",
      "Progreso: 3000/11771 frames (25.5%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:49\n",
      "Progreso: 3300/11771 frames (28.0%)\n",
      "\n",
      "Analizando paso 5 en tiempo 01:59\n",
      "Progreso: 3600/11771 frames (30.6%)\n",
      "\n",
      "Analizando paso 5 en tiempo 02:09\n",
      "Progreso: 3900/11771 frames (33.1%)\n",
      "\n",
      "Analizando paso 5 en tiempo 02:19\n",
      "Progreso: 4200/11771 frames (35.7%)\n",
      "\n",
      "Analizando paso 5 en tiempo 02:29\n",
      "Progreso: 4500/11771 frames (38.2%)\n",
      "Progreso: 4800/11771 frames (40.8%)\n",
      "Progreso: 5100/11771 frames (43.3%)\n",
      "Progreso: 5400/11771 frames (45.9%)\n",
      "Progreso: 5700/11771 frames (48.4%)\n",
      "Progreso: 6000/11771 frames (51.0%)\n",
      "Progreso: 6300/11771 frames (53.5%)\n",
      "Progreso: 6600/11771 frames (56.1%)\n",
      "Progreso: 6900/11771 frames (58.6%)\n",
      "Progreso: 7200/11771 frames (61.2%)\n",
      "Progreso: 7500/11771 frames (63.7%)\n",
      "Progreso: 7800/11771 frames (66.3%)\n",
      "Progreso: 8100/11771 frames (68.8%)\n",
      "Progreso: 8400/11771 frames (71.4%)\n",
      "Progreso: 8700/11771 frames (73.9%)\n",
      "Progreso: 9000/11771 frames (76.5%)\n",
      "Progreso: 9300/11771 frames (79.0%)\n",
      "Progreso: 9600/11771 frames (81.6%)\n",
      "Progreso: 9900/11771 frames (84.1%)\n",
      "Progreso: 10200/11771 frames (86.7%)\n",
      "Progreso: 10500/11771 frames (89.2%)\n",
      "Progreso: 10800/11771 frames (91.8%)\n",
      "Progreso: 11100/11771 frames (94.3%)\n",
      "Progreso: 11400/11771 frames (96.8%)\n",
      "Progreso: 11700/11771 frames (99.4%)\n",
      "\n",
      "Análisis guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos sin titulos\\analisis_video_2.txt\n",
      "Archivo procesado y guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_1_FINAL.txt\n",
      "Archivo procesado y guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_2_FINAL.txt\n",
      "Archivo procesado y guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_1_FINAL.txt\n",
      "Archivo procesado y guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_2_FINAL.txt\n",
      "Archivo procesado y guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_1_FINAL.txt\n",
      "Archivo procesado y guardado en: D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_2_FINAL.txt\n",
      "Analysis complete: The titles for the analyzed recipe steps have been successfully generated and formatted. Here is a summary of the processed files:\n",
      "\n",
      "1. **Analysis Video 1**:\n",
      "   - Input File: `D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos sin titulos\\analisis_video_1.txt`\n",
      "   - Output File: `D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_1_FINAL.txt`\n",
      "\n",
      "2. **Analysis Video 2**:\n",
      "   - Input File: `D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos sin titulos\\analisis_video_2.txt`\n",
      "   - Output File: `D:\\PruebatecnicaFerreycorp\\GenAI\\Videos y Receta\\Analisis de videos con especificaciones - FINAL\\analisis_video_2_FINAL.txt`\n",
      "\n",
      "The output files contain the steps with their new descriptive titles.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from swarm import Swarm, Agent\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function definitions for agents\n",
    "def process_recipe_images():\n",
    "    \"\"\"Function for RecetaAgent to process recipe images\"\"\"\n",
    "    agent = RecetaAgent()\n",
    "    directorio_base = \"D:\\\\PruebatecnicaFerreycorp\\\\GenAI\\\\Videos y Receta\"\n",
    "    directorio_imagenes = os.path.join(directorio_base, \"imagenes_receta\")\n",
    "    \n",
    "    if not os.path.exists(directorio_imagenes):\n",
    "        return {\"status\": \"error\", \"message\": f\"Directory not found: {directorio_imagenes}\"}\n",
    "    \n",
    "    resultados = agent.procesar_receta(directorio_imagenes)\n",
    "    agent.guardar_resultados(\"analisis_receta_detallado.json\")\n",
    "    return {\"status\": \"success\", \"data\": resultados}\n",
    "\n",
    "def analyze_videos():\n",
    "    \"\"\"Function for VideoAnalysisAgent to analyze videos\"\"\"\n",
    "    api_key = \"AIzaSyB_wQJWAwL9VzrYtF-P3Ipnz4rhp5KbalY\"\n",
    "    directorio_base = \"D:\\\\PruebatecnicaFerreycorp\\\\GenAI\\\\Videos y Receta\"\n",
    "    \n",
    "    # Crear carpeta para análisis sin títulos\n",
    "    carpeta_sin_titulos = os.path.join(directorio_base, \"Analisis de videos sin titulos\")\n",
    "    os.makedirs(carpeta_sin_titulos, exist_ok=True)\n",
    "    \n",
    "    agent = VideoAnalysisAgent(api_key)\n",
    "    videos = [\"preparacion1.mp4\", \"preparacion2.mp4\"]\n",
    "    results = []\n",
    "    \n",
    "    for i, video in enumerate(videos, 1):\n",
    "        ruta_video = os.path.join(directorio_base, video)\n",
    "        nombre_salida = os.path.join(carpeta_sin_titulos, f\"analisis_video_{i}.txt\")\n",
    "        agent.analizar_video(ruta_video, nombre_salida)\n",
    "        results.append({\"video\": video, \"output\": nombre_salida})\n",
    "    \n",
    "    return {\"status\": \"success\", \"data\": results}\n",
    "\n",
    "def generate_titles():\n",
    "    \"\"\"Function for TitleAnalysisAgent to generate titles\"\"\"\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        return {\"status\": \"error\", \"message\": \"OpenAI API key not found\"}\n",
    "    \n",
    "    directorio_base = \"D:\\\\PruebatecnicaFerreycorp\\\\GenAI\\\\Videos y Receta\"\n",
    "    carpeta_sin_titulos = os.path.join(directorio_base, \"Analisis de videos sin titulos\")\n",
    "    carpeta_con_titulos = os.path.join(directorio_base, \"Analisis de videos con especificaciones - FINAL\")\n",
    "    \n",
    "    # Crear carpeta para análisis con títulos\n",
    "    os.makedirs(carpeta_con_titulos, exist_ok=True)\n",
    "    \n",
    "    agent = TitleAnalysisAgent(api_key)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        archivo_entrada = os.path.join(carpeta_sin_titulos, f\"analisis_video_{i}.txt\")\n",
    "        archivo_salida = os.path.join(carpeta_con_titulos, f\"analisis_video_{i}_FINAL.txt\")\n",
    "        \n",
    "        if os.path.exists(archivo_entrada):\n",
    "            agent.procesar_archivo(archivo_entrada, archivo_salida)\n",
    "            results.append({\"input\": archivo_entrada, \"output\": archivo_salida})\n",
    "    \n",
    "    return {\"status\": \"success\", \"data\": results}\n",
    "\n",
    "def transfer_to_video_agent():\n",
    "    return video_agent\n",
    "\n",
    "def transfer_to_title_agent():\n",
    "    return title_agent\n",
    "\n",
    "# Create Swarm client\n",
    "client = Swarm()\n",
    "\n",
    "# Define agents\n",
    "recipe_agent = Agent(\n",
    "    name=\"Recipe Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are responsible for processing recipe images and extracting structured information.\n",
    "    Your main tasks are:\n",
    "    1. Process recipe images\n",
    "    2. Extract ingredients, tools, and steps\n",
    "    3. Generate a structured JSON output\n",
    "    \"\"\",\n",
    "    functions=[process_recipe_images, transfer_to_video_agent]\n",
    ")\n",
    "\n",
    "video_agent = Agent(\n",
    "    name=\"Video Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are responsible for analyzing cooking videos and comparing them with recipe steps.\n",
    "    Your main tasks are:\n",
    "    1. Process video frames\n",
    "    2. Compare actions with recipe steps\n",
    "    3. Generate analysis reports\n",
    "    \"\"\",\n",
    "    functions=[analyze_videos, transfer_to_title_agent]\n",
    ")\n",
    "\n",
    "title_agent = Agent(\n",
    "    name=\"Title Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are responsible for generating descriptive titles for recipe steps.\n",
    "    Your main tasks are:\n",
    "    1. Process analysis reports\n",
    "    2. Generate concise titles for each step\n",
    "    3. Create final formatted output\n",
    "    \"\"\",\n",
    "    functions=[generate_titles]\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "def run_recipe_analysis():\n",
    "    # Start with recipe agent\n",
    "    response = client.run(\n",
    "        agent=recipe_agent,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Process the recipe images and extract information\"}]\n",
    "    )\n",
    "    \n",
    "    # If recipe processing is successful, move to video analysis\n",
    "    if \"success\" in response.messages[-1][\"content\"]:\n",
    "        response = client.run(\n",
    "            agent=video_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Analyze the cooking videos and compare with recipe steps\"}]\n",
    "        )\n",
    "        \n",
    "        # If video analysis is successful, move to title generation\n",
    "        if \"success\" in response.messages[-1][\"content\"]:\n",
    "            response = client.run(\n",
    "                agent=title_agent,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Generate titles for the analyzed steps\"}]\n",
    "            )\n",
    "    \n",
    "    return response.messages[-1][\"content\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = run_recipe_analysis()\n",
    "    print(\"Analysis complete:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reto 3: Elaborar un Chatbot conectado a un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando el chatbot RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_1868\\4238844130.py:50: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferWindowMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Chatbot listo! \n",
      "        \n",
      "Puedo ayudarte a analizar datos de compras y clientes. Algunas preguntas que puedes hacer:\n",
      "- ¿Cuál es la edad promedio de los clientes?\n",
      "- ¿Cuántos ítems de la marca X se compraron el día Y?\n",
      "- ¿Qué significan las diferentes columnas del dataset?\n",
      "- ¿Quiénes compran más, los hombres o las mujeres?\n",
      "\n",
      "Escribe 'salir' para terminar.\n",
      "        \n",
      "Por favor, ingresa una pregunta.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: ANÁLISIS DE COLUMNAS:\n",
      "            Columna id:\n",
      "Estadísticas: Min=200000001, Max=200000500, Media=200000252.90\n",
      "Columna dia_visita:\n",
      "Estadísticas: Min=1, Max=730, Media=349.43\n",
      "Columna incidencia_compra:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna id_marca:\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna cantidad:\n",
      "Estadísticas: Min=0, Max=15, Media=0.69\n",
      "Columna ultima_marca_comprada:\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "-promo_marca_x :  Si la marca esta en promoción ese día\n",
      "-genero : genero del cliente \n",
      "-estado_civil : estado civil del cliente\n",
      "-edad : edad del cliente\n",
      "-nivel_educacion : nivel_educacion del cliente\n",
      "-ingreso_anual : ingreso anual del cliente\n",
      "-ocupacion : ocupacion del cliente\n",
      "-tamanio_ciudad : NO CONSIDERAR ESTA VARIABLE \n",
      "            \n",
      "            ANÁLISIS DE COLUMNAS:\n",
      "            Columna id:\n",
      "\n",
      "INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "\n",
      "Pregunta del usuario: hola\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Follow Up Input: hola como estas\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: ANÁLISIS DE COLUMNAS:\n",
      "            Columna id:\n",
      "Estadísticas: Min=200000001, Max=200000500, Media=200000252.90\n",
      "Columna dia_visita:\n",
      "Estadísticas: Min=1, Max=730, Media=349.43\n",
      "Columna incidencia_compra:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna id_marca:\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna cantidad:\n",
      "Estadísticas: Min=0, Max=15, Media=0.69\n",
      "Columna ultima_marca_comprada:\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "\n",
      "INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "Estadísticas: Min=0, Max=1, Media=0.34\n",
      "Columna promo_marca_2:\n",
      "Estadísticas: Min=0, Max=1, Media=0.32\n",
      "Columna promo_marca_3:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna promo_marca_4:\n",
      "Estadísticas: Min=0, Max=1, Media=0.12\n",
      "Columna promo_marca_5:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna genero:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna estado_civil:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "\n",
      "Pregunta del usuario:  ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Follow Up Input: como estas?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: ANÁLISIS DE COLUMNAS:\n",
      "            Columna id:\n",
      "Estadísticas: Min=200000001, Max=200000500, Media=200000252.90\n",
      "Columna dia_visita:\n",
      "Estadísticas: Min=1, Max=730, Media=349.43\n",
      "Columna incidencia_compra:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna id_marca:\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna cantidad:\n",
      "Estadísticas: Min=0, Max=15, Media=0.69\n",
      "Columna ultima_marca_comprada:\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "\n",
      "INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "Estadísticas: Min=0, Max=1, Media=0.34\n",
      "Columna promo_marca_2:\n",
      "Estadísticas: Min=0, Max=1, Media=0.32\n",
      "Columna promo_marca_3:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna promo_marca_4:\n",
      "Estadísticas: Min=0, Max=1, Media=0.12\n",
      "Columna promo_marca_5:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna genero:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna estado_civil:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "\n",
      "Pregunta del usuario:  ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Follow Up Input: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna precio_marca_1:\n",
      "Estadísticas: Min=1.1, Max=1.59, Media=1.39\n",
      "Columna precio_marca_2:\n",
      "Estadísticas: Min=1.26, Max=1.9, Media=1.78\n",
      "Columna precio_marca_3:\n",
      "Estadísticas: Min=1.87, Max=2.14, Media=2.01\n",
      "Columna precio_marca_4:\n",
      "Estadísticas: Min=1.76, Max=2.26, Media=2.16\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "Estadísticas: Min=0, Max=1, Media=0.34\n",
      "Columna promo_marca_2:\n",
      "Estadísticas: Min=0, Max=1, Media=0.32\n",
      "Columna promo_marca_3:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna promo_marca_4:\n",
      "Estadísticas: Min=0, Max=1, Media=0.12\n",
      "Columna promo_marca_5:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna genero:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna estado_civil:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "\n",
      "Pregunta del usuario:  ¿Puedes proporcionarme el número de ítems comprados de la marca 1 el día 10?\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Follow Up Input: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna precio_marca_1:\n",
      "Estadísticas: Min=1.1, Max=1.59, Media=1.39\n",
      "Columna precio_marca_2:\n",
      "Estadísticas: Min=1.26, Max=1.9, Media=1.78\n",
      "Columna precio_marca_3:\n",
      "Estadísticas: Min=1.87, Max=2.14, Media=2.01\n",
      "Columna precio_marca_4:\n",
      "Estadísticas: Min=1.76, Max=2.26, Media=2.16\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "Estadísticas: Min=0, Max=1, Media=0.34\n",
      "Columna promo_marca_2:\n",
      "Estadísticas: Min=0, Max=1, Media=0.32\n",
      "Columna promo_marca_3:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna promo_marca_4:\n",
      "Estadísticas: Min=0, Max=1, Media=0.12\n",
      "Columna promo_marca_5:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna genero:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna estado_civil:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "\n",
      "Pregunta del usuario:  ¿Puedes proporcionarme información sobre la cantidad promedio de ítems comprados de la marca 1 en el día 10 en general?\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Según los datos recuperados, en promedio se compran alrededor de 0.5 ítems de la marca 1 en el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, en promedio se compran alrededor de 0.5 ítems de la marca 1 en el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Follow Up Input: ¿Cuántos ítems de la marca 1 se compraron el día 20?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna precio_marca_1:\n",
      "Estadísticas: Min=1.1, Max=1.59, Media=1.39\n",
      "Columna precio_marca_2:\n",
      "Estadísticas: Min=1.26, Max=1.9, Media=1.78\n",
      "Columna precio_marca_3:\n",
      "Estadísticas: Min=1.87, Max=2.14, Media=2.01\n",
      "Columna precio_marca_4:\n",
      "Estadísticas: Min=1.76, Max=2.26, Media=2.16\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "\n",
      "INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "Estadísticas: Min=0, Max=1, Media=0.34\n",
      "Columna promo_marca_2:\n",
      "Estadísticas: Min=0, Max=1, Media=0.32\n",
      "Columna promo_marca_3:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna promo_marca_4:\n",
      "Estadísticas: Min=0, Max=1, Media=0.12\n",
      "Columna promo_marca_5:\n",
      "Estadísticas: Min=0, Max=1, Media=0.04\n",
      "Columna genero:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna estado_civil:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "Human: hola\n",
      "Assistant:  Hola, soy un asistente especializado en analizar datos de compras y comportamiento de clientes. A partir de la información proporcionada, puedo decir que el dataset se refiere a un estudio de compras en una tienda en particular. El dataset incluye información como el código del cliente, el día de la visita, si realizó una compra o no, la marca y cantidad comprada, la última marca y cantidad comprada, el precio de la marca, y algunas variables demográficas como género, estado civil, edad, nivel de educación e ingreso anual. Sin embargo, no se proporciona información sobre la variable \"tamaño de la ciudad\". ¿Puedo ayudarte con alguna otra pregunta relacionada con estos datos?\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, en promedio se compran alrededor de 0.5 ítems de la marca 1 en el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "\n",
      "Pregunta del usuario:  ¿En promedio, cuántos ítems de la marca 1 se compran en el día 20 según los datos recuperados?\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Según los datos recuperados, en promedio se compran alrededor de 0.84 ítems de la marca 1 en el día 20. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, en promedio se compran alrededor de 0.5 ítems de la marca 1 en el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 20?\n",
      "Assistant:  Según los datos recuperados, en promedio se compran alrededor de 0.84 ítems de la marca 1 en el día 20. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Follow Up Input: ¿Cuál es la edad promedio de los clientes?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mEres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
      "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
      "\n",
      "Contexto recuperado: Estadísticas: Min=0, Max=5, Media=0.84\n",
      "Columna ultima_cantidad_comprada:\n",
      "Estadísticas: Min=0, Max=1, Media=0.25\n",
      "Columna precio_marca_1:\n",
      "Estadísticas: Min=1.1, Max=1.59, Media=1.39\n",
      "Columna precio_marca_2:\n",
      "Estadísticas: Min=1.26, Max=1.9, Media=1.78\n",
      "Columna precio_marca_3:\n",
      "Estadísticas: Min=1.87, Max=2.14, Media=2.01\n",
      "Columna precio_marca_4:\n",
      "Estadísticas: Min=1.76, Max=2.26, Media=2.16\n",
      "Columna precio_marca_5:\n",
      "Estadísticas: Min=2.11, Max=2.8, Media=2.65\n",
      "Columna promo_marca_1:\n",
      "\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna estado_civil:\n",
      "Estadísticas: Min=0, Max=1, Media=0.39\n",
      "Columna edad:\n",
      "Estadísticas: Min=18, Max=75, Media=38.79\n",
      "Columna nivel_educacion:\n",
      "Estadísticas: Min=0, Max=3, Media=1.10\n",
      "Columna ingreso_anual:\n",
      "Estadísticas: Min=38247, Max=309364, Media=121841.64\n",
      "Columna ocupacion:\n",
      "Estadísticas: Min=0, Max=2, Media=0.77\n",
      "Columna tamanio_ciudad:\n",
      "Estadísticas: Min=0, Max=2, Media=0.66\n",
      "\n",
      "INFORMACIÓN DEL DATASET DE COMPRAS\n",
      "            \n",
      "            DICCIONARIO DE DATOS:\n",
      "            -id : Codigo del cliente\n",
      "-dia_visita : Número de día de la visita contando desde 0 (apertura de la tienda)\n",
      "-incidencia_compra : 0 si no compró durante la visita, 1 si compró algo\n",
      "-id_marca :  identificador de la marca\n",
      "-cantidad : Cantidad comprada\n",
      "-Ultima_marca_comprada : Ultima marca comprada\n",
      "-ultima_cantidad_comprada : ultima_cantidad_comprada\n",
      "-precio_marca_x : precio de la marca x\n",
      "\n",
      "Historial de la conversación:\n",
      "\n",
      "Human: hola como estas\n",
      "Assistant:  Claro, estoy a tu disposición para ayudarte con cualquier duda sobre estos datos. Puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. También puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. ¿En qué más puedo ayudarte?\n",
      "Human: como estas?\n",
      "Assistant:  Como asistente especializado en analizar datos de compras y comportamiento de clientes, puedo ayudarte a interpretar los resultados y a realizar análisis más específicos si lo necesitas. También puedo proporcionarte información sobre las estadísticas de las diferentes columnas, el contexto en el que se recuperó la información y el diccionario de datos que explica cada una de las variables. ¿En qué más puedo ayudarte?\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, no se proporciona información específica sobre el día 10. Sin embargo, en promedio, en el día 10 se compran 0.84 ítems en total, y la media de la cantidad comprada de la marca 1 es de 1.39. Por lo tanto, se puede estimar que se compran alrededor de 0.5 ítems de la marca 1 el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 10?\n",
      "Assistant:  Según los datos recuperados, en promedio se compran alrededor de 0.5 ítems de la marca 1 en el día 10. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "Human: ¿Cuántos ítems de la marca 1 se compraron el día 20?\n",
      "Assistant:  Según los datos recuperados, en promedio se compran alrededor de 0.84 ítems de la marca 1 en el día 20. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar dependiendo del día y del comportamiento de cada cliente.\n",
      "\n",
      "Pregunta del usuario:  ¿Cuál es la edad promedio de los clientes que compran en este conjunto de datos?\n",
      "\n",
      "Instrucciones adicionales:\n",
      "- Responde en español\n",
      "- Sé conciso pero informativo\n",
      "- Si no tienes suficiente información para responder, indícalo\n",
      "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
      "\n",
      "Tu respuesta:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Respuesta:  Según los datos recuperados, la edad promedio de los clientes que compran en este conjunto de datos es de 38.79 años. Sin embargo, es importante tener en cuenta que esta es solo una estimación y puede variar según el comportamiento de cada cliente. Además, es posible que existan otros factores que influyan en la edad de los clientes que compran, como la ubicación geográfica y el tipo de producto que compran.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "from openai import OpenAI as DirectOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = DirectOpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Define el template para el chatbot\n",
    "CUSTOM_PROMPT_TEMPLATE = \"\"\"Eres un asistente especializado en analizar datos de compras y comportamiento de clientes.\n",
    "Utiliza la siguiente información recuperada para responder la pregunta del usuario.\n",
    "\n",
    "Contexto recuperado: {context}\n",
    "\n",
    "Historial de la conversación:\n",
    "{chat_history}\n",
    "\n",
    "Pregunta del usuario: {question}\n",
    "\n",
    "Instrucciones adicionales:\n",
    "- Responde en español\n",
    "- Sé conciso pero informativo\n",
    "- Si no tienes suficiente información para responder, indícalo\n",
    "- Si la pregunta no está relacionada con los datos proporcionados, puedes responder de manera general pero apropiada\n",
    "\n",
    "Tu respuesta:\"\"\"\n",
    "\n",
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        # Initialize OpenAI with updated imports\n",
    "        self.llm = OpenAI(\n",
    "            temperature=0.7,\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        \n",
    "        # Initialize memory with correct configuration\n",
    "        self.memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True,\n",
    "            output_key='answer',\n",
    "            k=5\n",
    "        )\n",
    "        \n",
    "        # Load and process documents\n",
    "        self.vectorstore = self.create_vectorstore()\n",
    "        \n",
    "        # Create custom prompt\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"chat_history\", \"question\"],\n",
    "            template=CUSTOM_PROMPT_TEMPLATE\n",
    "        )\n",
    "        \n",
    "        # Create conversation chain with memory and custom prompt\n",
    "        self.chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=self.llm,\n",
    "            retriever=self.vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "            memory=self.memory,\n",
    "            combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "            return_source_documents=True,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    def create_vectorstore(self):\n",
    "        try:\n",
    "            # Load CSV data\n",
    "            df = pd.read_csv(r'D:\\PruebatecnicaFerreycorp\\GenAI\\Dataset\\compras_data.csv')\n",
    "            \n",
    "            # Convert important columns to string with descriptions\n",
    "            csv_text = \"\"\n",
    "            for column in df.columns:\n",
    "                csv_text += f\"Columna {column}:\\n\"\n",
    "                if pd.api.types.is_numeric_dtype(df[column]):\n",
    "                    csv_text += f\"Estadísticas: Min={df[column].min()}, Max={df[column].max()}, Media={df[column].mean():.2f}\\n\"\n",
    "                else:\n",
    "                    csv_text += f\"Valores únicos: {', '.join(map(str, df[column].unique()[:5]))}\\n\"\n",
    "                csv_text += \"\\n\"\n",
    "\n",
    "            # Load dictionary text\n",
    "            with open(r'D:\\PruebatecnicaFerreycorp\\GenAI\\Dataset\\Diccionario de Datos.txt', 'r', encoding='utf-8') as file:\n",
    "                dictionary_text = file.read()\n",
    "\n",
    "            # Combine texts with better structure\n",
    "            combined_text = f\"\"\"\n",
    "            INFORMACIÓN DEL DATASET DE COMPRAS\n",
    "            \n",
    "            DICCIONARIO DE DATOS:\n",
    "            {dictionary_text}\n",
    "            \n",
    "            ANÁLISIS DE COLUMNAS:\n",
    "            {csv_text}\n",
    "            \"\"\"\n",
    "\n",
    "            # Split text with smaller chunks\n",
    "            text_splitter = CharacterTextSplitter(\n",
    "                separator=\"\\n\",\n",
    "                chunk_size=500,\n",
    "                chunk_overlap=100,\n",
    "                length_function=len\n",
    "            )\n",
    "            texts = text_splitter.split_text(combined_text)\n",
    "\n",
    "            # Create vectorstore\n",
    "            return FAISS.from_texts(texts, self.embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al crear el vectorstore: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_question(self, question: str) -> str:\n",
    "        try:\n",
    "            # Use the new invoke method instead of calling directly\n",
    "            result = self.chain.invoke({\n",
    "                \"question\": question\n",
    "            })\n",
    "            \n",
    "            # Extract and return just the answer\n",
    "            return result.get(\"answer\", \"Lo siento, no pude generar una respuesta.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Lo siento, ocurrió un error al procesar tu pregunta: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    print(\"Inicializando el chatbot RAG...\")\n",
    "    try:\n",
    "        chatbot = RAGChatbot()\n",
    "        print(\"\"\"¡Chatbot listo! \n",
    "        \n",
    "Puedo ayudarte a analizar datos de compras y clientes. Algunas preguntas que puedes hacer:\n",
    "- ¿Cuál es la edad promedio de los clientes?\n",
    "- ¿Cuántos ítems de la marca X se compraron el día Y?\n",
    "- ¿Qué significan las diferentes columnas del dataset?\n",
    "- ¿Quiénes compran más, los hombres o las mujeres?\n",
    "\n",
    "Escribe 'salir' para terminar.\n",
    "        \"\"\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"\\nTu pregunta: \").strip()\n",
    "            \n",
    "            if not user_input:\n",
    "                print(\"Por favor, ingresa una pregunta.\")\n",
    "                continue\n",
    "                \n",
    "            if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "                print(\"¡Hasta luego!\")\n",
    "                break\n",
    "                \n",
    "            response = chatbot.process_question(user_input)\n",
    "            print(f\"\\nRespuesta: {response}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al inicializar el chatbot: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasql\n",
      "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandasql) (2.2.2)\n",
      "Requirement already satisfied: pandas in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandasql) (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandasql) (2.0.38)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandas->pandasql) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandas->pandasql) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from pandas->pandasql) (2025.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from sqlalchemy->pandasql) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from sqlalchemy->pandasql) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pandasql) (1.17.0)\n",
      "Building wheels for collected packages: pandasql\n",
      "  Building wheel for pandasql (pyproject.toml): started\n",
      "  Building wheel for pandasql (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26845 sha256=caa39a65273509ee78cd62df41a832aed931ab1dcd0cd8d5d6c5084f31d41b0f\n",
      "  Stored in directory: c:\\users\\diego\\appdata\\local\\pip\\cache\\wheels\\15\\a1\\e7\\6f92f295b5272ae5c02365e6b8fa19cb93f16a537090a1cf27\n",
      "Successfully built pandasql\n",
      "Installing collected packages: pandasql\n",
      "Successfully installed pandasql-0.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: colorama in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\pruebatecnicaferreycorp\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Chatbot Mediante Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando sistema de análisis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_29784\\1639356628.py:36: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferWindowMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema inicializado.\n",
      "Sistema de análisis de datos de compras iniciado.\n",
      "Escriba 'salir' para terminar la sesión.\n",
      "\n",
      "Ejemplos de consultas:\n",
      "- ¿Cuál es la distribución de compras por nivel educativo?\n",
      "- ¿Qué impacto tienen las promociones en las ventas por marca?\n",
      "- ¿Hay alguna relación entre el ingreso anual y la frecuencia de compra?\n",
      "- ¿Cuál es el comportamiento de compra según género y estado civil?\n",
      "--------------------------------------------------\n",
      "\n",
      "Respuesta: ¡Hola! ¿Cómo puedo asistirte hoy con el análisis de datos de ventas? Tengo información detallada sobre las compras realizadas por marca, así como datos demográficos de los clientes como género, estado civil, nivel de educación, ingreso anual y ocupación. ¿Hay algún aspecto específico en el que estés interesado, como el rendimiento de ventas de una marca en particular, o tal vez cómo las ventas se distribuyen entre diferentes grupos demográficos?\n",
      "\n",
      "Respuesta: ¡Hola! ¿Cómo puedo ayudarte hoy con tu análisis de datos de ventas? Tienes a tu disposición una gran cantidad de información, desde datos demográficos de los clientes hasta detalles de las compras realizadas. ¿Estás interesado en algún análisis en particular? Por ejemplo, podríamos explorar las tendencias de compra por género, estado civil, nivel de educación o ingreso anual. O tal vez quieras saber más sobre las tasas de conversión de las diferentes marcas. Por favor, proporciona más detalles para que pueda asistirte de la mejor manera posible.\n",
      "\n",
      "Obteniendo contexto relevante...\n",
      "\n",
      "Generando consulta SQL...\n",
      "\n",
      "Query generada: SELECT AVG(edad) AS 'Edad Promedio de los Clientes'\n",
      "FROM df;\n",
      "\n",
      "Ejecutando consulta...\n",
      "\n",
      "Analizando resultados...\n",
      "\n",
      "Respuesta: Resultados numéricos:\n",
      "   Edad Promedio de los Clientes\n",
      "0                      38.793962\n",
      "\n",
      "Análisis:\n",
      "1. Los resultados de la consulta indican que la edad promedio de los clientes es de aproximadamente 38.79 años. Este es un dato importante para entender el perfil demográfico de los clientes y puede ser útil para desarrollar estrategias de marketing y ventas dirigidas a este grupo de edad.\n",
      "\n",
      "2. Este hallazgo se relaciona con la variable 'edad' del diccionario de datos, que representa la edad del cliente. Es importante notar que este es un promedio, lo que significa que hay clientes de todas las edades, pero la mayoría tiende a estar cerca de los 38 años.\n",
      "\n",
      "3. No se pueden identificar patrones o tendencias específicas basándonos solo en este resultado. Sin embargo, si combinamos este dato con otras variables del diccionario de datos, como 'género', 'estado civil', 'nivel de educación', 'ingreso anual' y 'ocupación', podríamos obtener una imagen más completa del perfil del cliente.\n",
      "\n",
      "4. Desde el punto de vista del negocio, este insight es relevante porque nos permite entender mejor a nuestros clientes. Por ejemplo, si la mayoría de nuestros clientes tienen alrededor de 38 años, podríamos considerar la posibilidad de adaptar nuestras estrategias de marketing y ventas para atraer a este grupo de edad. Esto podría incluir la promoción de productos que sean populares entre este grupo de edad, o la adaptación de nuestra comunicación para resonar con ellos.\n",
      "\n",
      "5. No se observan anomalías o puntos interesantes en este resultado. Sin embargo, sería interesante explorar más a fondo los datos para ver si hay alguna correlación entre la edad y otras variables, como la marca preferida o la tasa de conversión. Por ejemplo, podríamos preguntarnos: ¿Los clientes de cierta edad tienden a comprar más de una marca específica? ¿La tasa de conversión es más alta entre los clientes de cierta edad? Estas son preguntas que podrían conducir a insights valiosos para el negocio.\n",
      "\n",
      "Obteniendo contexto relevante...\n",
      "\n",
      "Generando consulta SQL...\n",
      "\n",
      "Query generada: SELECT \n",
      "    CASE \n",
      "        WHEN genero = 0 THEN 'Mujer'\n",
      "        ELSE 'Hombre'\n",
      "    END AS Genero,\n",
      "    COUNT(*) AS Total_Compras\n",
      "FROM \n",
      "    df\n",
      "GROUP BY \n",
      "    genero\n",
      "ORDER BY \n",
      "    Total_Compras DESC;\n",
      "\n",
      "Ejecutando consulta...\n",
      "\n",
      "Analizando resultados...\n",
      "\n",
      "Respuesta: Resultados numéricos:\n",
      "   Genero  Total_Compras\n",
      "0   Mujer          36044\n",
      "1  Hombre          22649\n",
      "\n",
      "Análisis:\n",
      "1. EXPLICACIÓN DE LOS RESULTADOS:\n",
      "\n",
      "Los resultados de la consulta muestran que las mujeres realizan más compras que los hombres. En concreto, las mujeres han realizado 36,044 compras, mientras que los hombres han realizado 22,649 compras.\n",
      "\n",
      "2. RELACIÓN CON EL DICCIONARIO DE DATOS:\n",
      "\n",
      "El diccionario de datos nos proporciona la definición de cada variable. En este caso, la variable de interés es 'Género', que se codifica como 0 para Mujer y 1 para Hombre. Los resultados de la consulta se han obtenido sumando el total de compras realizadas por cada género.\n",
      "\n",
      "3. IDENTIFICACIÓN DE PATRONES O TENDENCIAS:\n",
      "\n",
      "El patrón más destacado es que las mujeres compran significativamente más que los hombres. De hecho, las mujeres realizan aproximadamente el 61.5% de las compras totales, mientras que los hombres realizan el 38.5% restante.\n",
      "\n",
      "4. INSIGHTS RELEVANTES PARA EL NEGOCIO:\n",
      "\n",
      "Este hallazgo puede ser muy relevante para el negocio. Por ejemplo, si la empresa está considerando lanzar una nueva campaña de marketing, podría ser beneficioso centrarse en las mujeres, ya que son las que realizan la mayoría de las compras. Además, podría ser útil investigar más a fondo las preferencias de compra de las mujeres para poder ofrecer productos que sean más atractivos para este grupo.\n",
      "\n",
      "5. ANOMALÍAS O PUNTOS INTERESANTES:\n",
      "\n",
      "No se observan anomalías en los datos. Sin embargo, es interesante notar la gran diferencia en el número de compras realizadas por mujeres y hombres. Esto podría sugerir que existen diferencias significativas en los comportamientos de compra entre los géneros. Sería útil realizar más investigaciones para entender mejor estas diferencias y cómo pueden ser aprovechadas por el negocio.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class AnalyticsRAG:\n",
    "    def __init__(self, csv_path, dict_path):\n",
    "        # Inicialización del modelo LLM\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=0.3,\n",
    "            model=\"gpt-4\",\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        \n",
    "        # Inicialización de embeddings\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        \n",
    "        # Cargar datos\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        with open(dict_path, 'r', encoding='utf-8') as file:\n",
    "            self.dictionary_text = file.read()\n",
    "        \n",
    "        # Configurar memoria del chat\n",
    "        self.memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True,\n",
    "            k=5\n",
    "        )\n",
    "        \n",
    "        # Template para queries SQL\n",
    "        self.query_template = \"\"\"\n",
    "        Basándote en el siguiente contexto y pregunta, genera una query SQL precisa.\n",
    "\n",
    "        CONTEXTO DEL DICCIONARIO:\n",
    "        {context}\n",
    "\n",
    "        PREGUNTA: {question}\n",
    "\n",
    "        La tabla se llama 'df' y debes:\n",
    "        1. Usar CASE WHEN para transformar variables categóricas a sus etiquetas descriptivas\n",
    "        2. Usar agregaciones apropiadas (COUNT, SUM, AVG, etc.)\n",
    "        3. Incluir filtros WHERE relevantes\n",
    "        4. Usar GROUP BY cuando sea necesario\n",
    "        5. Para porcentajes, multiplicar por 100 y redondear a 2 decimales\n",
    "\n",
    "        Genera SOLO la query SQL, sin explicaciones adicionales.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Template para análisis de resultados\n",
    "        self.analysis_template = \"\"\"\n",
    "        Analiza los siguientes resultados basándote en el contexto del diccionario de datos y la pregunta original.\n",
    "\n",
    "        CONTEXTO DEL DICCIONARIO:\n",
    "        {context}\n",
    "\n",
    "        PREGUNTA ORIGINAL: {question}\n",
    "\n",
    "        RESULTADOS DE LA CONSULTA:\n",
    "        {results}\n",
    "\n",
    "        INSTRUCCIONES:\n",
    "        1. Explica los resultados de manera clara y profesional\n",
    "        2. Relaciona los hallazgos con las definiciones del diccionario de datos\n",
    "        3. Identifica patrones o tendencias importantes\n",
    "        4. Proporciona insights relevantes para el negocio\n",
    "        5. Si hay anomalías o puntos interesantes, destácalos\n",
    "\n",
    "        Proporciona un análisis detallado y fundamentado.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inicializar vectorstore y chain\n",
    "        self.vectorstore = self._create_vectorstore()\n",
    "        \n",
    "    def _create_vectorstore(self):\n",
    "        \"\"\"Crea y retorna el vectorstore con la información del dataset y diccionario\"\"\"\n",
    "        dataset_info = self._generate_dataset_info()\n",
    "        combined_text = f\"\"\"\n",
    "        DICCIONARIO DE DATOS:\n",
    "        {self.dictionary_text}\n",
    "\n",
    "        INFORMACIÓN DEL DATASET:\n",
    "        {dataset_info}\n",
    "\n",
    "        MAPEOS DE VARIABLES:\n",
    "        - Género: 0=Mujer, 1=Hombre\n",
    "        - Estado Civil: 0=Soltero, 1=Casado, 2=Divorciado\n",
    "        - Nivel Educación: 0=Básica, 1=Media, 2=Superior, 3=Postgrado\n",
    "        - Ocupación: 0=Desempleado, 1=Empleado, 2=Independiente, 3=Jubilado\n",
    "        \"\"\"\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \", \"]\n",
    "        )\n",
    "        texts = text_splitter.split_text(combined_text)\n",
    "        \n",
    "        return FAISS.from_texts(texts, self.embeddings)\n",
    "    \n",
    "    def _generate_dataset_info(self):\n",
    "        \"\"\"Genera información estadística básica del dataset\"\"\"\n",
    "        info = []\n",
    "        info.append(f\"Total registros: {len(self.df)}\")\n",
    "        info.append(f\"Período analizado: Días {self.df['dia_visita'].min()} a {self.df['dia_visita'].max()}\")\n",
    "        info.append(f\"Total clientes únicos: {self.df['id'].nunique()}\")\n",
    "        compras = self.df[self.df['incidencia_compra'] == 1]\n",
    "        info.append(f\"Total compras realizadas: {len(compras)}\")\n",
    "        info.append(f\"Tasa de conversión global: {(len(compras)/len(self.df))*100:.2f}%\")\n",
    "        \n",
    "        # Estadísticas por marca\n",
    "        info.append(\"\\nEstadísticas por marca:\")\n",
    "        for marca in range(1, 6):\n",
    "            compras_marca = compras[compras['id_marca'] == marca]\n",
    "            info.append(f\"Marca {marca}: {len(compras_marca)} compras\")\n",
    "        \n",
    "        return \"\\n\".join(info)\n",
    "    \n",
    "    def _get_context_for_question(self, question):\n",
    "        \"\"\"Obtiene el contexto relevante del vectorstore para una pregunta\"\"\"\n",
    "        docs = self.vectorstore.similarity_search(question, k=3)\n",
    "        return \"\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    def _generate_sql_query(self, question, context):\n",
    "        \"\"\"Genera una query SQL basada en la pregunta y el contexto\"\"\"\n",
    "        try:\n",
    "            query_response = self.llm.invoke(\n",
    "                self.query_template.format(\n",
    "                    context=context,\n",
    "                    question=question\n",
    "                )\n",
    "            )\n",
    "            query = query_response.content.strip()\n",
    "            \n",
    "            # Limpiar la query de marcadores markdown\n",
    "            query = query.replace('```sql', '').replace('```', '').strip()\n",
    "            \n",
    "            if \"SELECT\" not in query.upper():\n",
    "                return None\n",
    "                \n",
    "            # Verificar y corregir nombres de columnas\n",
    "            query = query.replace('precio_marca_x', 'precio_marca_1')\n",
    "            query = query.replace('promo_marca_x', 'promo_marca_1')\n",
    "            \n",
    "            print(f\"\\nQuery generada: {query}\")  # Para debugging\n",
    "            return query\n",
    "        except Exception as e:\n",
    "            print(f\"Error en generación de query SQL: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _execute_sql_query(self, query):\n",
    "        \"\"\"Ejecuta una query SQL y retorna los resultados\"\"\"\n",
    "        try:\n",
    "            if query:\n",
    "                local_env = {'df': self.df}\n",
    "                result = sqldf(query, local_env)\n",
    "                if len(result) > 0:\n",
    "                    return result\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error en ejecución de query SQL: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _analyze_results(self, question, results, context):\n",
    "        \"\"\"Analiza los resultados usando el contexto del diccionario\"\"\"\n",
    "        try:\n",
    "            analysis_response = self.llm.invoke(\n",
    "                self.analysis_template.format(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    results=results.to_string()\n",
    "                )\n",
    "            )\n",
    "            return analysis_response.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error en análisis de resultados: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def process_question(self, question):\n",
    "        \"\"\"Procesa una pregunta y retorna una respuesta analítica\"\"\"\n",
    "        try:\n",
    "            # Primero, determinar si la pregunta requiere análisis de datos\n",
    "            sql_keywords = [\n",
    "                'cuántos', 'promedio', 'total', 'porcentaje', 'comparar', \n",
    "                'máximo', 'mínimo', 'distribución', 'tendencia', 'cantidad',\n",
    "                'ventas', 'compras', 'precio', 'mayor', 'menor', 'más', 'menos',\n",
    "                'análisis', 'estadísticas', 'comportamiento', 'impacto'\n",
    "            ]\n",
    "            \n",
    "            needs_analysis = any(keyword in question.lower() for keyword in sql_keywords)\n",
    "            \n",
    "            if not needs_analysis:\n",
    "                # Si es una pregunta conversacional, usar el LLM directamente\n",
    "                context = self._get_context_for_question(question)\n",
    "                response = self.llm.invoke(\n",
    "                    f\"\"\"Actúa como un asistente experto en análisis de datos de ventas.\n",
    "                    Contexto del sistema: {context}\n",
    "                    \n",
    "                    Pregunta del usuario: {question}\n",
    "                    \n",
    "                    Proporciona una respuesta profesional y ayuda al usuario a formular preguntas \n",
    "                    más específicas si es necesario.\"\"\"\n",
    "                )\n",
    "                return response.content\n",
    "            \n",
    "            # Si requiere análisis, proceder con la generación de SQL\n",
    "            print(\"\\nObteniendo contexto relevante...\")\n",
    "            context = self._get_context_for_question(question)\n",
    "            \n",
    "            print(\"\\nGenerando consulta SQL...\")\n",
    "            query = self._generate_sql_query(question, context)\n",
    "            if not query:\n",
    "                return \"No se pudo generar una consulta SQL válida para tu pregunta.\"\n",
    "            \n",
    "            print(\"\\nEjecutando consulta...\")\n",
    "            sql_result = self._execute_sql_query(query)\n",
    "            if sql_result is None or sql_result.empty:\n",
    "                return \"No se encontraron resultados para tu consulta.\"\n",
    "            \n",
    "            # 3. Analizar resultados\n",
    "            print(\"\\nAnalizando resultados...\")\n",
    "            analysis = self._analyze_results(question, sql_result, context)\n",
    "            if not analysis:\n",
    "                return \"Error al analizar los resultados.\"\n",
    "            \n",
    "            # 4. Formatear respuesta final\n",
    "            response = f\"Resultados numéricos:\\n\"\n",
    "            response += f\"{sql_result.to_string()}\\n\\n\"\n",
    "            response += f\"Análisis:\\n{analysis}\"\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error en el procesamiento: {str(e)}\"\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Inicia la interfaz de conversación\"\"\"\n",
    "        print(\"Sistema de análisis de datos de compras iniciado.\")\n",
    "        print(\"Escriba 'salir' para terminar la sesión.\")\n",
    "        print(\"\\nEjemplos de consultas:\")\n",
    "        print(\"- ¿Cuál es la distribución de compras por nivel educativo?\")\n",
    "        print(\"- ¿Qué impacto tienen las promociones en las ventas por marca?\")\n",
    "        print(\"- ¿Hay alguna relación entre el ingreso anual y la frecuencia de compra?\")\n",
    "        print(\"- ¿Cuál es el comportamiento de compra según género y estado civil?\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            question = input(\"\\nConsulta: \").strip()\n",
    "            \n",
    "            if question.lower() in ['salir', 'exit', 'quit']:\n",
    "                print(\"\\nSesión finalizada.\")\n",
    "                break\n",
    "                \n",
    "            if not question:\n",
    "                continue\n",
    "                \n",
    "            response = self.process_question(question)\n",
    "            print(\"\\nRespuesta:\", response)\n",
    "\n",
    "def initialize_analytics():\n",
    "    \"\"\"Función principal para inicializar el sistema\"\"\"\n",
    "    csv_path = r\"D:\\PruebatecnicaFerreycorp\\GenAI\\Dataset\\compras_data.csv\"\n",
    "    dict_path = r\"D:\\PruebatecnicaFerreycorp\\GenAI\\Dataset\\Diccionario de Datos.txt\"\n",
    "    \n",
    "    print(\"Inicializando sistema de análisis...\")\n",
    "    analytics = AnalyticsRAG(csv_path, dict_path)\n",
    "    print(\"Sistema inicializado.\")\n",
    "    \n",
    "    analytics.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_analytics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
